\chapter{Discussion}
\label{ch:discussion}





\section{Conclusions}
\label{sec:conclusions}
This thesis has made the following contributions.

A ``flailing detector'' to aid teachers in real-time classroom orchestration is possible, and a simple algorithm demonstrating this detector was provided. This algorithm operated on pre-recorded data, not real-time, but an argument was made that an real-time implementation for classroom use is plausible. 

Fine-grained snapshots based on code edit operations provided a large amount of data for analysis. From these data, metrics were extracted that lead to specific insights. These insights led to the Particle Analysis Method, which provided a fast, useful metric on student progress within an activity, if the activity was constrained to having a known, canonical solution.

This work provided an extractor implementation for the particle analysis method, and argued that it could be implemented to perform in real-time in production systems.

In post-hoc analysis, particle scores were visualized to easily see the trajectories of progress experienced by students. 

A Classroom Console prototype was provided that can be used as starting point for developing teacher-facing orchestration tools. This console was critiqued by experienced teachers through interviews, and found to possess many favorable attributes, some that the author did not predict. These features were provided as a list of observations made by the teachers. The teachers also made many feature requests, which were also included here to inform future console work. 

The teachers requested analysis and reporting after the fact in addition to the real-time console, which would allow them to tune their activities, provide reporting to their leadership, and look for long-term patterns in student development. 

A number of additional features were identified that would further improve the accuracy of flailing detector, such as looking for off-topic strings as a sign of lack of problem traction. Many language- and implementation-specific improvements were also identified to improve the method. This method and its tools are not heavily dependent on language-specific features or work flows, and can be ported to work with any Blockly-based language immediately, and can be used to inform particle analysis implementations in other block, visual, and textual language environments.

%\section{Recommendations} 
% \label{sec:recommendations}
% We do not recommend using Git as a database. Further recommendations of leGitimate scientific and educational merit will be added as part of the full dissertation.


\section{Future Work}
\label{sec:futurework}

As previously mentioned, there is ample future work to be done in understanding the reasoning behind behavior choices, with particular support to mis-attribution of failure and success. Investigation into this mis-attribution should be conducted, to use traditional methods of assessing student mindset combined with the power of fine-grain snapshot analysis. 

The change-type features that were extracted from these data would likely be useful in a study where an independent variable describing a behavior of interest could be collected. Such an experiment could be looking for off-task behavior, comparing expert and novice patterns, studying a particular class of common mistake, or any other pattern. With tightly-controlled observations to record the ground truth of the behavior in question, change-type data such as these could be mined against that ground truth to find corresponding relationships. 

A teacher-ready product using particle analysis would consist of a library of solution particle definitions matching activities from the curriculum. The curriculum for App Inventor is largely stable, if varied, and creating solution particle definitions for the most common assignments would benefit teachers active in many different curriculum programs. 

Adding custom definitions of solution particles to match specific activities would require, in its current form, a researcher or developer to design the particles. However, this is not due to the particles being difficult to imagine, but the degree of complexity of the tools with which the particles are currently defined. The elements that make up particles are already defined, abstracted entities that do not require direct manipulation of the underlying blocks representation. One slight exception is the ``close enough'' text comparator, described in Section \ref{sec:close-enough-text}, which was hard-coded with allowable edit distances. It would require a bit more generalization to meet the other elements. But with some wrapping and smoothing, a small language could be developed to express all possibilities of solution particles in a way that would be more accessible to curriculum developers. An even better tool would be able to capture a solution directly from App Inventor and disassemble it into constituent particles automatically. This tool would be the most accessible, and anyone who knows App Inventor to also define canonical solutions for use in the particle analyzer, and with that, the classroom console. 

%\subsection{Classroom Console and Learning Management Systems}
%TODO

\subsection{Towards Programming Skill Assessment}
This study focused entirely on the time frame within a single programming activity. The goal, as previous stated, was to empower the teacher to best orchestrate their resources during the lab session. The tools developed here can grow to fill goals beyond this. If a course were to have all of the closed-ended activities in the curriculum instrumented with particle analysis and the classroom console, data would be collected for each as they are conducted. This would create a new sort of student portfolio, where each activity's progress over time could be displayed, and their progress patterns could be seen and analyzed over the greater time span of the whole course. This could serve multiple purposes, the first of which would be to assess a particular student's vector over the course. If their rate of improvement within activities falls off, for instance, these data may provide insight to help isolate what factor caused that behavior. That same collection of data could also be used to assess the activities themselves by analyzing many or all students' progress charts for a certain activity. This could be used to find common sticking or failure points, or areas that are generally easy. The teacher knowing this could then iterate their activity design, scaffolding, or both. Further down this line of possibilities, it may be be possible to isolate particular skills, and identify which are exercised by different activities, which could lead to an improved understanding of how those skills develop over the course of a curriculum.

\subsection{Solution Particles as Indicators for Further Analysis}
The particle analysis method is, at its core, a feature extractor for snapshot data. For every snapshot, it provides an indicator of progress. That measure of progress has potential to be used to advance real-time classroom tools, and to inform future research. 

One example would be to use solution particle scores as an indicator for same-state. If a student returns to an identical or near-identical state of their code, that student may be experiencing some sort of flailing, in the form of a non-productive iterative behavior. Detecting a return to a previous state is certainly possible from snapshot data. The particle scores could serve as a beacon, and could be used as a signal to automatically deploy the same-state-checking algorithm. The solution scores could reduce the set of possible comparisons for a given snapshot state dramatically, likely allowing it be performed in real-time. This measure could be added to the classroom console or other teacher analytic tool to add richness to the teacher's view of the students' behavior. 
%TODO find some lit references about same-state detection in programming?

The particle score could also be used as a variable for future experiments, and could help to uncover patterns of other properties that correspond with progress made, stalled, or regressed. One such study could take the scores over time in post-hoc data, and encode periods of those histories into states abstract states, describing patterns in the scores, such as flat changes (active non-improvement), fast progress, and regression. These states could be used in in a machine learning experiment to extract correlating patterns in other data, similar to \citet{tissenbaummodeling}, hopefully revealing properties that may be related to those behaviors.

One such design could use a Hidden Markov Model to determine the threshold for automatic flailing detection. This auto-detection could then flag students above threshold in the Classroom Console, further aiding the teacher in deciding where to direct their resources. Inputs to this method would be the particle score graph, or segments of it, with specific measures extracted: interval since last frame, score increase, score decrease, or score the same. 

Further investigation should be given to conditions where students ``win'' at flailing--- when a non-advancing set of changes yields advancement. This may be possible with the data from this study. Hypotheses include that flailing/play periods will be different per assignment, and there may be a method, such as the one in the above paragraph, to determine what is reasonable for a particular assignment. 

It may also be possible to use instrumentation to detect the spread of code artifacts through a classroom, which could be indicative of integrity, or simply teach us how concepts propagate through a student population. Just looking at code playback, there are projects that intuitively ``look like'' they might be engaged in copying solutions. This intuition is based on sudden appearance of code artifacts after somewhat long periods of inactivity. 

\subsection{Reducing Overhead of Activity Setup}
Teacher efficacy improvement is the ultimate goal of the Classroom Console and the particle analysis method. \citet{sudol2012calculating} developed a probabilistic approach using Markov Models that measured the student's current distance from the right answer, which is conceptually similar to the particle analysis method presented here. Using such a model to reduce the overhead in developing activity solution definitions would be beneficial, as teachers could develop and deploy activities themselves. Further study with additional collection of data will be necessary to develop and train such a probabilistic model, but with the work of \citet{sudol2012calculating}, it is likely tractable. 

\subsection{Better Fine-grained Collection of Snapshot Data} 
In this work, the entire project was captured on every change, which created a need to reverse-engineer what changes occurred between snapshots post-facto. Upcoming updates to Blockly will allow for easier access to succinct event descriptions, potentially allowing only the changes themselves to be sent, effectively reducing the transmission payload and increasing transparency of collected data. Such improvements can make future collection experiments easier, and provide data that is richer for analysis, with no loss in accuracy. 

\subsection{Novice and Expert Behaviors}
There is also work to be done in assessing expert and novice usage patterns using snapshot analysis. \cite{petre-1995} outlined a strong difference in reading and authoring skills pertaining to secondary notation between expert and novice users. Teaching App Inventor, like any language, includes showing patterns that are good standards of practice, in hopes of the student developing more expert skills. Those patterns are not yet based on scientific observation of expert and novice programming behaviors. Snapshot analysis may be critical to provide insight into expert patterns, which could then be disseminated to enhance teaching practice. 

\section{Final Remarks}
In addition to its findings, this dissertation provided methods of data collection and analysis for education research. Beginner computer science learners will continue to use online, high-level programming environments in formal education settings, informally in camps, and on their own. There is immense potential in the near future to advance the understanding and modeling of the computer science learning using the data that can be collected from those students. Continued inquiry and analysis may lead to further insights into the learning process, and from there, as this dissertation purports, to concrete tools that teachers may use to improve their efficacy in teaching. 

