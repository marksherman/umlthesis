\chapter{Background}
\label{chap:background}

\section{App Inventor}
\label{sec:app-inventor-background}
App Inventor is an online development environment to build android apps, employing a drag-and-drop designer and graphical, blocks-based code editing. The App Inventor language and runtime uses a purely event-driven programming model, where all functions are driven by events and event handler code \citep{turbak-2014}. The event handlers elicits code that has small, purpose-specific procedures, even with complete novices, as it is the only way to access the features App Inventor provides to the programmer.

Constructionism \citep{papert1991situating} covers a wide class of discovery-based pedagogical vehicles. App Inventor follows in this tradition, deeply influenced by Scratch \citep{resnick2009scratch}, and offers low barriers for entry, high ceilings of capability, and a built-in library of powerful abstractions.

\section{Graphical Languages}
\label{sec:graphical-languages}

Much of the literature concerning programming efficacy was done at a time when visual languages were emerging as a purported panacea of usefulness \citep{shu-1988}, but with little empirical evidence to substantiate those claims \citep{petre-1995}. This is not particularly endemic to visual languages, evidenced by many historic complaints, including \citet{sch-1980}, ``Computer scientists... make broad claims for the simplicity, naturalness, or ease-of-use of new computer languages or techniques, but do not take advantage of the opportunity for experimental confirmation.'' Speaking of diagram-based visual languages \citet{blackwell-2001} offered a challenge to researchers to support their claims of intuition through visual programming, ``...to explain why this intuition may be valid, and to propose the ways in which, if it is valid, it can most be effectively exploited.'' Consider that challenge accepted.

But first, some background on Cognitive Dimensions.


\subsection{Cognitive Dimensions of Notations} \label{sec:CDs}
The Cognitive Dimensions of Notations framework was developed over many years, most formally canonized in \citet{blackwell-2003}. This framework provided a vocabulary for interface designers that offered a comprehensible, broad evaluation to discuss how a language suits its users needs. Their mission was for this vocabulary to be easily applicable, understandable, and most importantly, be theoretically coherent. 

The cognitive dimensions framework presented an empirically-derived set of dimensions that can be generally measured for a given class of user activity. These dimensions described different cognitive mechanisms that are necessary for the user to execute a given action, and helped create a meaningful dialog about how those dimensions can be traded to optimize the action for the user \citep{blackwell-2003}. The research was started to investigate why some notations work and don't work for the people using them \citep{petre-2006}. 

The dimensions alone do not constitute anything. A dimension is not good or bad. Dimensions are part of the framework's instrument, which includes evaluation of relevant dimensions for a particular task. Application of the the dimensions to a set of representative tasks is what drives the apparatus, and the assessment is in the comparison of the desired dimensionality for those tasks compared to the observed value of those dimensions for the task. This also makes it possible to use the cognitive dimensions framework, in a constrained form, as a user survey tool, to provide users with a method for describing their experience with a notation system.

Without any further fanfare, here are the dimensions, in their entirety as of \citeyear{blackwell-2003}:
\begin{description}
\item [Viscosity] Resistance to change, or difficulty to make a change. Modifying heading styles across a document manually is a viscous activity, in that the user's desired action is seemingly simple, but the effort to execute it is significant.
\item [Visibility] Ability to view components easily. This dimensions is often traded away in languages in favor of, for example, abstractions.
\item [Premature commitment] Constraints placed on the order of doing things. In programming, a mechanic of premature commitment forces the programmer to make decisions before they have the information to base the decision on. \citet{roast-2000} described this as "the user having to satisfy the secondary goal prior to achieving the primary goal."
\item [Hidden dependencies] Entities may cite each other, and a change in one entity may create change elsewhere unexpectedly due ot unapparent citations. This is common in spreadsheets, where cell references are not easily visible.
\item [Role-expressiveness] The purpose of an entity is readily inferred. The reader can discover the author's intent. 
\item [Error-proneness] Invites mistakes. Can be protected with preventative mechanisms.  
\item [Abstractions] Change the underlying notation. Common examples are macros, functions, global find-and-replace, word processor styles, and even speed dial. They can be persistent (macros) or transient (find and replace). An abstraction manager is necessary if the user is allowed to edit the abstractions. 
\item [Secondary notation] Information encoded in means other than the formal syntax. 
\item [Closeness of mapping] How closely the notation relates to the result it describes. 
\item [Consistency] Similar semantics are expressed in similar syntactic forms. Information can be obscured by inconsistent presentation.
\item [Diffuseness] Verbosity of the language. Large icons, long phrases, and other forms of graphical real estate consumption contribute to diffuseness. I do not know why this dimensions isn't called verbosity, which could easily be contrasted by calling low verbosity succinct.
\item [Hard mental operations] Creates high demand on cognitive resources. This is an interesting dimension, as it makes clear to designers that sometimes a notation can force a user to work things out in their head, or otherwise tax working memory.
\item [Provisionality] Provisional notation, meaning temporary, allows for low commitment to a notation. This may be useful for sketching, recording potential options, ``what if'' exercises, and general exploration activities.
\item [Progressive evaluation] Work can be checked at any time. Evaluation is an important part of the design process, and drives iteration \citep{atman-2003}. A well-known advantage to interpreted programming environments is their ease of work evaluation, where the user can try out partially-completed programs at any time, and have meaningful interactions with their partial work.
\end{description}


\subsection{Secondary Notation}
One of these dimensions in particular, secondary notation, emerged as especially important to visual programming \citep{petre-2006}. The work at the time was focused on diagram programming, such as LabVIEW, where researchers found a distinct and repeating signal that differentiated experts from novices. That signal was in the use of secondary notation, where experts would use arrangement and layout of the diagram itself to convey information not encoded in the formal notation. 

Secondary notation is, generally, any notation that's not part of the formal notation, and may include comments and whitespace in text languages, layout in diagrams, proximity in blocks languages, and much more. Often, secondary notation can be used however the user likes, and therefore can be used to record information that the designer of the notation did not anticipate. \citet{petre-1995} claimed that much of the comprehensibility of graphical programming is in the secondary notation, and \citet{raymond-1991} conjectured, even earlier, that the layout of a visual program was the most important, and possibly only, aspect that was truly visual. Of course, \citeauthor{raymond-1991} had a very specific meaning of ``visual,'' where it depended on being non-discrete, unable to guarantee syntactic or semantic differentiation, similar to the mathematical notion of continuity or the electronic notion of analog. In fact, \citeauthor{raymond-1991} called such a language Analog, and contrasted it against Notational languages, which were discrete, with strongly differentiable notational marks and strongly differentiable conceptual objects being represented. This distinction of Notational versus Analog language was developed earlier as part of an interesting philosophical discussion on notations, and asked hard questions about denotation and representation \citep{goodman-1976}. This discussion had nothing to do with programming, nor visual programming, but it was brought into that domain by \citeauthor{raymond-1991}, and nearly predicted the findings of the expert and novice usage difference in secondary notation, found later by \citet{petre-2006}.



\section{Behaviors when Encountering Difficulty}
\label{sec:behaviors}
Novice programmers are faced with a plethora of difficulties to overcome. \citet{perkins-1986} identified some key behavior patterns students may show when they encounter difficulty. To begin, \citeauthor{perkins-1986} observed that most students displayed ``significant powers of invention'' when working with programming tasks, and they employed that inventiveness in tackling problems they encountered. However, there were are an enormous number of pitfalls in the programming process that interfered with that inventiveness leading to a reasonable degree of competence. 

The general behavior patterns that \citet{perkins-1986} identified are as follows. There were two conceptual cohorts: \emph{stoppers} and \emph{movers.} When a stopper found themselves without an immediate answer to a difficulty, they felt at a complete loss, and were unwilling to further explore the problem. They would completely stop working, often sitting back from the computer. This behavior is extremely common, and has been personally observed by the author. A stopper can be rescued with immediate intervention, where a teacher can assess and ask the next questions explicitly (such as ``what do you think that error means?''), and press the student for answers. With this sort of intervention, stoppers usually found a solution for their difficulty, and were able to resume. In the observations of \citeauthor{perkins-1986}, the activities were short, so a rescued stopper could make it successfully to the end of the activity with only one intervention. But that intervention was timely, asserted immediately when the student stopped progressing, which allowed the researcher to re-direct the student without a loss of context. Such an intervention in a regular classroom would require a large amount of teacher time per student. Outside of a research environment, this could be difficulty to reliably achieve.

Opposite of the stoppers were the movers, who were identified by a collection of traits, pivoting around the lack of fear to try things, and the lack of frustration if things do not work. Movers consistently tried one idea after another, and never stopped long enough to appear to be stuck. This may sound like a generally desirable behavior pattern over the stoppers, but the movers also had difficulties. Extreme movers moved too fast, modifying without reflection, resulting in changes to their code that clearly did not work. These extreme movers did not appear to draw lessons from their failed ideas, nor did they display behavior of honing in towards a solution. They appeared emotionally distant from the task, where \citeauthor{perkins-1986} conjectured that the keyboard and screen served as a ``handy distraction,'' allowing students to keep themselves busy without having to stop and think. The author claims this behavior to be akin to \emph{fidgeting,} although \citeauthor{perkins-1986} did not use that term. An extreme mover may actually be a stopper, we reason, but instead of acknowledging their seemingly insurmountable barrier, they fidget with their code until time expires.

\citet{perkins-1986} further expanded on a specific behavior of a mover, \emph{tinkering.} This word is often associated with tools that are intentionally friendly to discovery through experimentation and bottom-up design, such as Scratch \citep{resnick2009scratch}. \citeauthor{perkins-1986} maintained a more sterile definition, devoid of positive or negative connotation-- tinkering is simply the behavior of making many small changes to a program in hopes of getting it to work.

Tinkering sometimes presented a decidedly negative pattern, where the student wrongly assumed that some minor change was required to achieve their goal, and did not engage in deep thought about the problem. This was often seen alongside poor tracking skills, where the student did not follow what the code they were writing would actually do. The student never stopped to question their understanding of how the program, or the machine under it, worked.

The skill of questioning one's own understanding could be considered advanced. Executing ``good tracking,'' as \citet{perkins-1986} put it, actually relies on an understanding beneath the code syntax. The concept of the \emph{notional machine,} as introduced by \citet{duboulay-1986}, describes the underlying mechanism of the programming language that students are truly attempting to master. \citeauthor{duboulay-1986} observed that the notional machine is usually not taught at all, with attention instead going to the syntax and structure of language, without concern for the device it represented. \citeauthor{duboulay-1986} intended to empower educators with the notional machine, and encouraged teachers to build their pedagogy to expose it. 

The worst case of tinkering was observed when students accumulated multiple untested changes, or did not remove failed changes, which eventually rendered the problem incomprehensible. Any computer science instructor has likely seen the end result of such a pattern. But can tinkering in this understanding can be effective. \citeauthor{perkins-1986} used an analogy from a nearby domain. A tinkerer can easily become stuck in a local maxima, where the solution appears to be close at hand, but is actually not obtainable without significant rework. In this case the student was at the top of a small hill, the wrong hill, and would need to climb back down that hill, and up a better hill that could go higher. This was identified as a particularly tempting and insidious pattern- when a program appears to be nearly correct, but in reality requires work greater than a series of small modifications. If a student was on the correct hill, where the local maxima was also the global maxima and goal, then tinkering could be effective, if done systematically. That maxima still needed to be found, even if it was nearby.

Comparing that school of thought to the Lifelong Kindergarten's tinkering in Scratch, it first appears inconsistent. It is possible, however, that Scratch, and other constructionist learning environments, always put students on the correct hill. This could be done by heavy restriction of the domain, such as the intentionally narrow activities of Code.org. More so, they may be so well optimized for bottom-up design practices that there are no hills. Local maximas would be nearly impossible, as the goal state, and global maxima, are being defined by the student progressively as they work up towards it. 

%TODO this paragraph must belong somewhere...
A student's degree of comfort in the classroom has been shown to be factor in CS1 undergrad success \citep{wilson-2002}. Comfort level was measured by a collection of factors, revolving around likelihood to ask questions (demonstrating comfort) and signs of anxiety (demonstrating discomfort). That study found other factors that had significance with course success. The third-most significant factor was \emph{attribution to luck,} but it was a negative parameter. Many students, for reasons unclear, blamed their successes or failures on the unstable attribute of luck. Whether they chose to do this for failure or success correlated with different mental attitudes towards their self-efficacy. If a student was unhappy with their score, and attributed their failures to luck, it provided motivation to continue trying. However, attribution to luck, whether happy or unhappy, had a strong negative impact on their scores ($p=0.233$). This attribution to luck may be a parameter that contributes to the flailing/tinkering behavior, as it could be interpreted as not taking responsibility for the success or failure of the program. 


\section{Programming Environment Instrumentation}
Building instrumentation into an IDE is a method to ``get inside'' the process students go through while programming. Such instrumentation can capture a vast number of intermediate states of an assignment, allowing researchers to see the process that went into a product, instead of having to conjecture based purely on the final artifacts. The idea is decades old \citep{spohrer1985goal}, but has shown significant growth in the last five years, likely due to increased ubiquity of high-speed Internet and self-contained student development environments. One current and ongoing project is Blackbox, a repository of instrumented activity collected from instances of the BlueJ IDE, which has taken the concept to a worldwide scope \citep{brown2014blackbox}. 

\citet{piech-2012} took a very straightforward approach to generating these in-progress data. They modified the development environment used in a CS1 course to take a \emph{snapshot} every time the student compiled their code. This snapshot was a complete version of the program at that time. Every snapshot was committed to a local git repository, so that at the end of the assignment the repository contained a full history of the project's code, from the very first words typed to completion. Recording snapshots on every save was a logical choice, as it was a good indication that the student had something they deemed ready for evaluation. \citet{lipman-phd} did similarly with his instrumentation in LearnCS, where snapshots were captured to a git repository on every save and run (where run effectively included compile). These studies looked at projects in Java and C respectively, which are languages that use the same write-compile-run model. Other languages, such as App Inventor, do not, and require different semantics as to when a snapshot should be triggered.


%\section{Teacher Dashboards}
\label{sec:teacher-dashboards}

%\section{This Study}

